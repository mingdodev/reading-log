## 시스템 최적화로 성능을 높이고 비용 효율화하기

### 시맨틱 캐싱

- 의미적으로 동일한 요청에 대해 LLM 호출을 재사용함으로써, 응답 지연을 줄이고 API 비용을 절감할 수 있다.

- 특히 기존 데이터가 충분히 축적된 서비스에서는, 미리 캐싱 셋을 구성해 초기 응답 성능을 안정화하는 데 유리하다.

- 짧고 구조화된 입력의 경우, 임베딩 차원 축소를 통해 캐시 비교 비용을 낮추는 전략도 고려할 수 있다.

> 책의 사례는 채팅 서비스에서 반복적으로 축적되는 대화 로그를 기반으로, 대화 흐름에 맞는 다음 문장을 추천하는 것이 목적이었다. 대화 유형이 일정한 패턴으로 반복되며, 전체 문장 분포를 사전에 구조화할 수 있는 환경이므로 비지도 군집화(DBSCAN)를 활용해 의미적으로 유사한 문장들을 묶는 방식이 적합했다.  
> 반면 쓰기 피드백 시스템은 실시간으로 입력되는 문장에 대해 가장 유사한 오류 사례 5개를 즉시 검색하는 것이 목적이다. 입력 문장과 결과 간의 대응 관계가 명확하고, 안정적인 top-k 반환이 중요하므로 군집화 없이 코사인 유사도 기반 검색 방식을 채택하였다.