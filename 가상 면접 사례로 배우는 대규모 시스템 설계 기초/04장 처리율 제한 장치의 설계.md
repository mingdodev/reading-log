## 처리율 제한 장치 (rate limiter)

- 클라이언트 또는 서비스가 보내는 트래픽의 처리율을 제한. 임계치를 넘어서면 추가로 도달한 모든 요청은 block됨.

#### 장점

- **DoS 공격에 의한 자원 고갈을 방지할 수 있다.**

    - 예. 트위터는 3시간 동안 300개 트윗만 올릴 수 있으며, 구글 독스 API는 사용자당 분당 300회의 읽기 요청만 허용한다.

- 비용을 절감한다.

    - 우선순위가 높은 API에 자원을 더 할당할 수 있고, 외부 API 호출에 따른 과금이 발생한다면 이를 제한할 수 있다.

- 서버 과부하를 막는다. 봇(bot)에서 오는 트래픽이나 사용자의 잘못된 이용 패턴으로 유발된 트래픽을 거른다.

> 봇으로 자동화한 무의미한/민감 경로를 스캔하려는 요청이 거의 초당 1회 꼴로 들어온 적이 있었는데, 이때는 의심되는 트래픽의 IP를 특정 시간동안 차단하여 문제에 대응했다. 민감 경로와 같이 위협이 잠재된 요청이 아닌 정상 경로로도 공격이 가능하니, 처리율 제한 장치를 두어 과부하를 막을 수 있을 것이다. 또, 이런 경우 모니터링 도구 등을 활용하여 메일로 경고가 오도록 자동화해둘 수 있다.

#### 구현 계획

- 제한 범위는 IP별? 사용자별? API 엔드포인트별? 서비스별?

- 위치
    
    - 서버측: 클라이언트측에서 구현 시 위변조 가능

    - 미들웨어: 클라우드 마이크로서비스라면 API Gateway(SSL 종단, 처리율 제한, 사용자 인증, IP 허용 목록 관리 등)에 구현

    - 요청 횟수 초과시 HTTP 429 반환 (Too many requests)

- 알고리즘
    
    - 토큰 버킷: 일정 시간마다 공급되는 토큰을 소비하는 방식
    
    - 누출 버킷: FIFO로 동작하는 큐가 꽉 차 있으면 요청이 전달되지 않음

    > 이건 '하루에 300개 포스트 작성'과 같은 제한을 구현하기에는 적절하지 않아보인다. 단시간에 발생하는 과도한 요청을 안정적인 속도로 처리하도록 제어할 수 있다. 요청 처리 주기도 너무 길게 잡으면 오히려 지연으로 작용할 것이니 원하는 처리율에 따라 설정해야 할 것 같다. 반대로 단기간에 트래픽이 뛰는 서비스에서는 요청 처리가 밀리면 최신 요청이 버려진다는 단점이 있다.

    - 고정 윈도 카운터: 정해진 간격의 타임라인마다 윈도우가 열리고, 윈도우 카운터에 요청 개수가 기록. 값이 임계치에 도과하면 요청을 버림

    - 이동 윈도 로깅: 윈도우 경계에서 트래픽이 몰릴 수 있는 고정 윈도의 문제점을 해결, 메모리를 많이 쓰는 대신 어느 순간을 바라봐도 처리율이 일정하게 유지됨

#### 세부 구현

- 메모리(Redis 등 활용)에 버킷 별 카운터 저장

- 메시지별 처리율에 대한 정의는 설정 파일 형태로 디스크에 저장

- 한도 이상의 요청은 버려져야 하는가, 트래픽 안정화 후 처리되기 위해 대기열에 보관해야 하는가?

- 처리율 제한 장치가 사용하는 HTTP 헤더: 남은 처리 가능 요청 수, 윈도마다 전송할 수 있는 요청 수, 몇 초 뒤에 다시 보내야하는지를 클라이언트에게 헤더로 반환

- **분산 시스템에서 처리율 제한을 구현하려면**

    - 경쟁 해결: 루아 스크립트, 레디스의 정렬 집합 자료구조 사용

    > 락이 보편적으로 떠오르지만, 락은 시스템 성능을 상당히 떨어뜨린다. 루아 스크립트로 레디스를 원자성 있게 쓸 수 있다고 한다. [이거는 분산 환경에서 특정 요청의 성공률을 계산하기 위해 슬라이딩 윈도우를 구현하는 방법, 레디스와 루아스크립트를 원자성을 위해 활용한다는 점에서 참고할 수 있는 글](https://mangkyu.tistory.com/356)

    - 동기화: 고정 세션 대신 공통 저장소로서 Redis를 쓰자.

    - 성능 최적화와 모니터링